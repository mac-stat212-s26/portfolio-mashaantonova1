[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "COMP/STAT212 Portfolio",
    "section": "",
    "text": "Welcome to my online portfolio for COMP/STAT112 course taken at Macalester College. Please, use the side bar on the left for navigation.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Welcome</span>"
    ]
  },
  {
    "objectID": "pv/pv-01.html",
    "href": "pv/pv-01.html",
    "title": "Professional Viz",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Prof Viz",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Professional Viz</span>"
    ]
  },
  {
    "objectID": "tt/2025-07-08.html",
    "href": "tt/2025-07-08.html",
    "title": "TidyTuesday Sample 1",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>TidyTuesday Sample 1</span>"
    ]
  },
  {
    "objectID": "tt/2025-07-15.html",
    "href": "tt/2025-07-15.html",
    "title": "TidyTuesday Sample 2",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>TidyTuesday Sample 2</span>"
    ]
  },
  {
    "objectID": "tt/hw01-tt.html",
    "href": "tt/hw01-tt.html",
    "title": "Homework 01",
    "section": "",
    "text": "TidyTuesday Section\nExplore the week‚Äôs TidyTuesday challenge. Develop a research question, then answer it through a short data story with effective visualization(s). Provide sufficient background for readers to grasp your narrative.",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Homework 01</span>"
    ]
  },
  {
    "objectID": "tt/hw01-tt.html#importing-the-data-set",
    "href": "tt/hw01-tt.html#importing-the-data-set",
    "title": "Homework 01",
    "section": "Importing the Data Set",
    "text": "Importing the Data Set\n\nCodelibrary(tidyverse)\nlibrary(tidytuesdayR)\nlibrary(viridis)\n\ntuesdata &lt;- tt_load(\"2026-01-27\")\n\ncompanies &lt;- tuesdata$companies\nlegal_nature &lt;- tuesdata$legal_nature\nqualifications &lt;- tuesdata$qualifications\nsize &lt;- tuesdata$size",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Homework 01</span>"
    ]
  },
  {
    "objectID": "tt/hw01-tt.html#research-question",
    "href": "tt/hw01-tt.html#research-question",
    "title": "Homework 01",
    "section": "Research Question",
    "text": "Research Question\nHow is access to high levels of declared capital structured across Brazilian firms, and how do ownership roles and legal form shape capital concentration?",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Homework 01</span>"
    ]
  },
  {
    "objectID": "tt/hw01-tt.html#background",
    "href": "tt/hw01-tt.html#background",
    "title": "Homework 01",
    "section": "Background",
    "text": "Background\nBrazil maintains a public registry of legal entities through the Cadastro Nacional da Pessoa Jur√≠dica (CNPJ), published by the Brazilian Ministry of Finance (Receita Federal). This TidyTuesday dataset is curated from the CNPJ open data and cleaned to focus on firms with meaningful declared capital stock, retaining only companies above a capital threshold.\nDeclared capital stock represents the financial capital formally reported by a firm and serves as a proxy for economic scale. Companies are categorized by size and legal form, and the dataset also includes information on owner qualifications. This allows us to examine not only which companies hold the highest capital but also how ownership roles and organizational structure relate to capital distribution.\nBecause the dataset excludes very low-capital firms and capital stock is highly right-skewed, this analysis uses logarithmic scaling and distribution-based visualizations to avoid misleading comparisons. The goal is descriptive: to examine patterns of capital concentration across firm types, ownership, and legal structure.",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Homework 01</span>"
    ]
  },
  {
    "objectID": "tt/hw01-tt.html#main-visualization-owner-qualification-vs-elite-capital-status",
    "href": "tt/hw01-tt.html#main-visualization-owner-qualification-vs-elite-capital-status",
    "title": "Homework 01",
    "section": "Main Visualization: Owner qualification vs elite capital status",
    "text": "Main Visualization: Owner qualification vs elite capital status\n\nCodeowner_comparison &lt;- companies %&gt;%\n  filter(!is.na(owner_qualification), !is.na(capital_stock), capital_stock &gt; 0) %&gt;%\n  mutate(elite_threshold = quantile(capital_stock, 0.90),\n    is_elite = if_else(capital_stock &gt;= elite_threshold, \"Elite (Top 10%)\", \"Other Companies\")) %&gt;%\n\n  add_count(owner_qualification, name = \"owner_count\") %&gt;%\n  filter(owner_count &gt;= sort(unique(owner_count), decreasing = TRUE)[5]) %&gt;%\n  group_by(owner_qualification, is_elite) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(is_elite) %&gt;%\n  mutate(percent = count / sum(count) * 100)\n\nggplot(owner_comparison, aes(x = reorder(owner_qualification, percent), y = percent, fill = is_elite)) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  labs(title = \"Distribution of Capital by Owner Qualification\",\n    subtitle = \"Comparing elite (top 10%) and typical Brazilian companies\",\n    x = \"Owner Qualification\",\n    y = \"Share of Companies (%)\",\n    fill = \"Company Type\",\n    caption = \"Source: TidyTuesday (2026-01-27) companies.csv\") +\n  scale_fill_viridis_d(option = \"B\")  + \n  theme_minimal()",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Homework 01</span>"
    ]
  },
  {
    "objectID": "tt/hw01-tt.html#supporting-visualization-legal-nature-vs-capital-among-small-enterprises",
    "href": "tt/hw01-tt.html#supporting-visualization-legal-nature-vs-capital-among-small-enterprises",
    "title": "Homework 01",
    "section": "Supporting Visualization: Legal nature vs capital among small enterprises",
    "text": "Supporting Visualization: Legal nature vs capital among small enterprises\n\nCodecompanies %&gt;%\n  filter(company_size == \"small-enterprise\") %&gt;%\n  filter(!is.na(capital_stock), capital_stock &gt; 0) %&gt;%\n  mutate(log_capital_stock = log10(capital_stock),\n    legal_nature = as.factor(legal_nature)) %&gt;%\n  ggplot(aes(x = log_capital_stock, y = legal_nature, fill = legal_nature)) +\n  geom_boxplot() +\n  guides(fill = \"none\") +\n  scale_color_viridis_d() +\n  labs(title = \"Capital Stock Across Legal Forms in Small Enterprises\",\n    subtitle = \"Log10-transformed capital stock by legal structure\",\n    x = \"Capital Stock (Log10 Scale)\",\n    y = \"Legal Form\",\n    caption = \"Source: TidyTuesday (2026-01-27) companies.csv\") +\n  theme_minimal()",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Homework 01</span>"
    ]
  },
  {
    "objectID": "tt/hw01-tt.html#summary-data-story",
    "href": "tt/hw01-tt.html#summary-data-story",
    "title": "Homework 01",
    "section": "Summary / Data Story",
    "text": "Summary / Data Story\nOur analysis explores how access to high levels of declared capital is structured across Brazilian firms, focusing on the roles of ownership and legal form.\nWho controls the capital? The main visualization shows the distribution of owner qualifications in elite (top 10% by capital) versus typical companies. While Managing Partners dominate most firms, elite companies reveal a more diverse leadership composition: Administrators and Managers lead roughly 30% of elite firms compared to under 9% in typical firms, and positions like Directors, Officers, and Presidents are also far more common at the top. This indicates that the highest-capital firms adopt more formalized corporate governance structures, suggesting ownership type is strongly associated with access to substantial capital.\nHow does legal structure shape capital within small enterprises? Because capital stock is highly right-skewed, values were placed on a log10 scale for meaningful comparison and to avoid the largest firms dominating the plot. The supporting boxplot examines capital stock across legal forms among small enterprises. While most legal categories show similar median capital levels, Limited Liability Companies (LLCs) display a wider distribution and longer right tail, indicating that some LLCs hold much higher capital than their peers. Simpler forms, such as sole proprietorships and partnerships, tend to have narrower ranges and fewer extreme values. This suggests that while legal form does not completely determine capital, it can create opportunities for higher capital accumulation within certain structures.\nKey insight: Taken together, these findings suggest that access to high capital in Brazil is structured more by ownership role and organizational form than by formal size classification. Elite capital is concentrated in firms with diverse, professionalized leadership and in legal structures (especially LLCs) that allow for greater financial leverage. Entrepreneurs and policymakers should be aware that both governance and legal framework influence which firms can access the highest levels of capital.",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Homework 01</span>"
    ]
  },
  {
    "objectID": "tt/hw02-tt.html",
    "href": "tt/hw02-tt.html",
    "title": "Homework 02",
    "section": "",
    "text": "TidyTuesday Section (optional)\nExplore the week‚Äôs TidyTuesday challenge. Develop a research question, then answer it through a short data story with effective visualization(s). Provide sufficient background for readers to grasp your narrative.\nCodelibrary(tidyverse)\nlibrary(tidytuesdayR)\nlibrary(viridis)\n\ntuesdata &lt;- tt_load(\"2026-02-10\")\n\nschedule &lt;- tuesdata$schedule",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Homework 02</span>"
    ]
  },
  {
    "objectID": "tt/hw02-tt.html#tidytuesday-section-optional",
    "href": "tt/hw02-tt.html#tidytuesday-section-optional",
    "title": "Homework 02",
    "section": "",
    "text": "ImportantInstructions\n\n\n\nYou can count work on this week‚Äôs TidyTuesday toward the exceptional work required for an A in the Homework component.",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Homework 02</span>"
    ]
  },
  {
    "objectID": "tt/hw02-tt.html#research-question",
    "href": "tt/hw02-tt.html#research-question",
    "title": "Homework 02",
    "section": "Research Question",
    "text": "Research Question\nHow are Olympic events distributed across sport disciplines and medal status, and how does scheduling intensity vary over the course of the Games?",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Homework 02</span>"
    ]
  },
  {
    "objectID": "tt/hw02-tt.html#background",
    "href": "tt/hw02-tt.html#background",
    "title": "Homework 02",
    "section": "Background",
    "text": "Background\nThe Milan‚ÄìCortina 2026 Winter Olympics schedule dataset contains detailed timing and venue information for all competition and training sessions across winter sport disciplines. Each row represents a single scheduled event, including whether it is a medal event, a training session, and the day of the week on which it occurs.\nBecause the Olympics run over a concentrated time window with thousands of scheduled sessions, understanding how events are distributed across sports and across days provides insight into which disciplines dominate the schedule and when competitive intensity peaks. Rather than focusing on individual performances, this analysis explores how the structure of the Olympic calendar allocates time, venues, and attention among different sports.\nThe goal is descriptive: to examine patterns in event volume by discipline and the timing of medal competitions throughout the Games.",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Homework 02</span>"
    ]
  },
  {
    "objectID": "tt/hw02-tt.html#main-visualization-which-disciplines-host-the-most-events",
    "href": "tt/hw02-tt.html#main-visualization-which-disciplines-host-the-most-events",
    "title": "Homework 02",
    "section": "Main Visualization: Which disciplines host the most events?",
    "text": "Main Visualization: Which disciplines host the most events?\n\nCodediscipline_counts &lt;- schedule %&gt;%\n  group_by(discipline_name) %&gt;%\n  summarise(total_events = n(), .groups = \"drop\") %&gt;%\n  arrange(desc(total_events)) %&gt;%\n  slice_head(n = 12)\n\nggplot(discipline_counts,\n       aes(x = reorder(discipline_name, total_events),\n           y = total_events,\n           fill = total_events)) +\n  geom_col() +\n  coord_flip() +\n  scale_fill_viridis_c() +\n  labs(\n    title = \"Olympic Events by Sport Discipline\",\n    subtitle = \"Disciplines with the highest number of scheduled sessions\",\n    x = \"Sport Discipline\",\n    y = \"Number of Events\",\n    caption = \"Source: TidyTuesday (2026-02-10) schedule.csv\") +\n  theme_minimal()",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Homework 02</span>"
    ]
  },
  {
    "objectID": "tt/hw02-tt.html#supporting-visualization-medal-vs-non-medal-events-across-the-games",
    "href": "tt/hw02-tt.html#supporting-visualization-medal-vs-non-medal-events-across-the-games",
    "title": "Homework 02",
    "section": "Supporting Visualization: Medal vs non-medal events across the Games",
    "text": "Supporting Visualization: Medal vs non-medal events across the Games\n\nCodedaily_medals &lt;- schedule %&gt;%\n  group_by(date, is_medal_event) %&gt;%\n  summarise(total_events = n(), .groups = \"drop\")\n\nggplot(daily_medals,\n       aes(x = date, y = total_events, color = is_medal_event)) +\n  geom_line(linewidth = 1) +\n  scale_color_viridis_d(labels = c(\"Non-medal Events\", \"Medal Events\")) +\n  labs(\n    title = \"Daily Event Volume During the 2026 Winter Olympics\",\n    subtitle = \"Comparison of medal and non-medal sessions by day\",\n    x = \"Date\",\n    y = \"Number of Events\",\n    color = \"Event Type\",\n    caption = \"Source: TidyTuesday (2026-02-10) schedule.csv\") +\n  theme_minimal()",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Homework 02</span>"
    ]
  },
  {
    "objectID": "tt/hw02-tt.html#summary-data-story",
    "href": "tt/hw02-tt.html#summary-data-story",
    "title": "Homework 02",
    "section": "Summary / Data Story",
    "text": "Summary / Data Story\nThis analysis examines how the 2026 Winter Olympics schedule allocates events across sports and across time.\nWhich sports dominate the Olympic calendar? The main visualization shows that a small group of disciplines account for a large share of total scheduled events. Sports such as Alpine Skiing, Cross-Country Skiing, Biathlon, and Ice Hockey host substantially more sessions than others, reflecting their multiple rounds, heats, and training requirements. These sports require repeated venue usage and extended competition formats, leading to a heavier scheduling footprint compared to single-event disciplines.\nHow does competitive intensity evolve across the Games? The supporting line chart reveals that medal events are not evenly distributed across days. Early days feature a high proportion of training and preliminary sessions, while medal events increase toward the middle and later stages of the Olympics. This pattern suggests a buildup of competitive stakes as qualification rounds conclude and championship events begin.\nKey insight: The Olympic schedule is shaped less by the number of sports and more by the structure of each discipline. Endurance and tournament-style sports dominate total event volume, while medal competitions cluster later in the Games. This highlights how organizational design, not just sport popularity, determines how time and resources are distributed during the Olympics.",
    "crumbs": [
      "TidyTuesday",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Homework 02</span>"
    ]
  },
  {
    "objectID": "pcl/pcl.html",
    "href": "pcl/pcl.html",
    "title": "Pre-Class Learning Summaries",
    "section": "",
    "text": "R",
    "crumbs": [
      "Pre-Class Learnings",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pre-Class Learning Summaries</span>"
    ]
  },
  {
    "objectID": "pcl/pcl.html#quarto",
    "href": "pcl/pcl.html#quarto",
    "title": "Pre-Class Learning Summaries",
    "section": "Quarto",
    "text": "Quarto\n\n\n\nfrom qmd4sci.njtierney.com",
    "crumbs": [
      "Pre-Class Learnings",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pre-Class Learning Summaries</span>"
    ]
  },
  {
    "objectID": "ica/ica-sample1.html",
    "href": "ica/ica-sample1.html",
    "title": "ICA Sample 1",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>ICA Sample 1</span>"
    ]
  },
  {
    "objectID": "ica/ica-sample2.html",
    "href": "ica/ica-sample2.html",
    "title": "ICA Sample 2",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>ICA Sample 2</span>"
    ]
  },
  {
    "objectID": "ica/03-adv-ggplot-notes.html",
    "href": "ica/03-adv-ggplot-notes.html",
    "title": "3 Adv Data Viz",
    "section": "",
    "text": "üß© Learning Goals\nBy the end of this lesson, you should be able to:",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>3 Adv Data Viz</span>"
    ]
  },
  {
    "objectID": "ica/03-adv-ggplot-notes.html#learning-goals",
    "href": "ica/03-adv-ggplot-notes.html#learning-goals",
    "title": "3 Adv Data Viz",
    "section": "",
    "text": "Navigate ggplot2 reference page to find needed functions for a desired visualization\nNavigate the different sections of a function help page to construct desired plot features, in particular,\n\nNavigate the Usage section to identify arguments that must be set\nNavigate the Arguments section to understand how arguments work\nNavigate the Aesthetics section to learn how plot appearance can be controlled\nNavigate the Examples section for some usage examples\n\n\nIdentify when to use different data arguments within ggplot() and geom_() layers",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>3 Adv Data Viz</span>"
    ]
  },
  {
    "objectID": "ica/03-adv-ggplot-notes.html#introduction",
    "href": "ica/03-adv-ggplot-notes.html#introduction",
    "title": "3 Adv Data Viz",
    "section": "Introduction 1\n",
    "text": "Introduction 1\n\nIn this lesson, we are going to recreate NYTimes 2015 Temperature Visualization (html) using data from San Francisco (SFO) in 2011.\n\n\nScreenshot of NYTimes 2015 Temperature Visualization",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>3 Adv Data Viz</span>"
    ]
  },
  {
    "objectID": "ica/03-adv-ggplot-notes.html#reading-data",
    "href": "ica/03-adv-ggplot-notes.html#reading-data",
    "title": "3 Adv Data Viz",
    "section": "Reading Data",
    "text": "Reading Data\nRun the code chunk below to load the tidyverse package and read in the San Francisco weather data.\n\nCodelibrary(tidyverse)\nweather &lt;- read_csv(\"https://mac-stat.github.io/data/sfo_weather.csv\")",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>3 Adv Data Viz</span>"
    ]
  },
  {
    "objectID": "ica/03-adv-ggplot-notes.html#understanding-data",
    "href": "ica/03-adv-ggplot-notes.html#understanding-data",
    "title": "3 Adv Data Viz",
    "section": "Understanding Data",
    "text": "Understanding Data\nBelow is the codebook of the data. Familiarize yourself with the meaning of each variable. Use the codebook as a reference when using the data.\n\n\nMonth: Month of the year (1-12)\n\nDay: Day within the month (1-31)\n\nLow/High: Low/high temperature this day\n\nNormalLow/NormalHigh: Typical low/high temperature for this day of the year\n\nRecordLow/RecordHigh: Record low/high temperature for this day of the year\n\nLowYr/HighYr: Year in which the record low/high was observed\n\nPrecip: Amount of precipitation (inches) this day\n\nRecordPrecip: Record amount of precipitation for this day of the year\n\nPrecipYr: Year in which the record precipitation was observed\n\ndate: The actual date in 2011 for this day in YYYY-MM-DD format\n\ndateInYear: What day of the year is it? (1-365)\n\nRecord: Logical (TRUE/FALSE) indicating whether this day had a high temperature record\n\nRecordText: Text that displays the record high for this day (\"Record high: ##\")\n\nRecordP: Logical (TRUE/FALSE) indicating whether this day had a precipitation record\n\nCulmPrec: Cumulative precipitation for the month up to this day",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>3 Adv Data Viz</span>"
    ]
  },
  {
    "objectID": "ica/03-adv-ggplot-notes.html#exercise-1",
    "href": "ica/03-adv-ggplot-notes.html#exercise-1",
    "title": "3 Adv Data Viz",
    "section": "Exercise 1",
    "text": "Exercise 1\nExamine the NYTimes 2015 Temperature Visualization (html) then answer the following questions.\nData Storytelling\n\nRelate the intro paragraph: ‚ÄúScientists declared that 2015 was Earth‚Äôs hottest year on record‚Ä¶‚Äù to the design of the visualization. In particular, based on the intro paragraph,\n\nWhat key message/claim does NYTimes want readers to be able to explore?\nHow did this goal inform what information is displayed in the visualization?\n\n\n\nThe visualization tells the story that 2015 was significantly warmer than normal by comparing daily temperatures in each city to historical averages and records. By showing the full temperature range across the year and highlighting deviations from the normal band, it allows readers to explore how persistent and widespread the warming was locally.\nAesthetic Mapping\n\nWhat specific variables (from the data codebook) underlie the visualization?\nHow do these variables map to aesthetics of the visual elements, eg, position, size, shape, and color of glyphs?\n\nThe main variables mapped are daily high and low temperatures, normal historical ranges, record extremes, and time across the year. These are encoded through position on the x-axis (date), vertical range bars for temperature, shaded bands for normal values, and color to emphasize warmer-than-normal periods, with precipitation shown as cumulative area/lines below.",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>3 Adv Data Viz</span>"
    ]
  },
  {
    "objectID": "ica/03-adv-ggplot-notes.html#exercise-2",
    "href": "ica/03-adv-ggplot-notes.html#exercise-2",
    "title": "3 Adv Data Viz",
    "section": "Exercise 2",
    "text": "Exercise 2\nNavigate the Geoms section of the ggplot2 reference page to find a geom that corresponds to the visual elements in the temperature plot. Using both the small thumbnail visuals on the right and the names of the geom‚Äôs, brainstorm some possibilities for geom‚Äôs you might use to recreate the temperature visualization.\n\n\n\n\n\n\nNoteNavigating Documentation / Reference Pages\n\n\n\nYou need to navigate the geoms further by opening up their reference pages to understand if a particular geom is suitable for our task. Let‚Äôs look at the geom_point documentation page to learn how to read a documentation page..\nThe Usage section shows all of the possible inputs (arguments) to the geom. These are all of the ways that a geom can be customized. Just looking at the argument names can help give a hint as to what arguments might fit our needs.\nThe Arguments section, on the other hand, explains in detail what each argument does and the possible values the argument can take. The mapping, data, and ... arguments will be the most commonly used by far.\n\n\nmapping is the argument that is being used when we specify which variables should link or map to the plot aesthetics (the code inside aes()).\n\ndata is the argument where we specify the dataset containing the variables that the geom is using.\n\n... is used for fixed aesthetics (ones that don‚Äôt correspond to a variable), eg, to set the color of all points, we use color = \"red\" and to set the size of all points, we use size = 3.\n\nThe Aesthetics section of a geom documentation page gives information on how the visual elements of the geom correspond to data. For example, the geom_point documentation page shows that x and y aesthetics are available. It also shows some new aesthetics like stroke.\n\n\n\n\n\n\n\n\nNotedata Argument\n\n\n\nPreviously you have used one dataset per plot by specifying that as the first argument of ggplot(). However, multiple data sets can be passed into ggplot as shown in the example below.\n\nCodedata(diamonds)\n\ndiamonds_avg_price &lt;- diamonds |&gt;\n  group_by(carat) |&gt;\n  summarize(avg_price = mean(price)) |&gt;\n  arrange(carat)\ndiamonds_avg_price &lt;- diamonds_avg_price[seq(1, nrow(diamonds_avg_price), 3), ]\n\nggplot(diamonds, aes(x = carat, y = price)) +\n  geom_point() +\n  geom_point(\n    data = diamonds_avg_price,\n    aes(x = carat, y = avg_price),\n    color = \"deepskyblue\",\n    size = 3\n  )\n\n\n\n\n\n\n\n\n\nLook at the geom_linerange documentation page and start off your temperature visualization with the record lows and highs. Your plot should look like the one below. The hex code of the used light tan color is #ECEBE3.\n\n\nSFO Weather Records in 2011\n\n\nCodeggplot(weather) +\n  geom_linerange(\n    aes(\n      x = dateInYear,\n      ymin = RecordLow,\n      ymax = RecordHigh\n    ),\n    color = \"#ECEBE3\"\n  ) +\n    theme_classic()\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipKeyboard Shortcuts\n\n\n\nAs you work on this plot, try to use some new keyboard shortcuts. Focus on the following:\n\nInsert code chunk: Ctrl+Alt+I (Windows). Option+Command+I (Mac).\nRun current code chunk: Ctrl+Shift+Enter (Windows). Command+Shift+Return (Mac).\nRun current line/currently selected lines: Ctrl+Enter (Windows). Command+Return (Mac).",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>3 Adv Data Viz</span>"
    ]
  },
  {
    "objectID": "ica/03-adv-ggplot-notes.html#exercise-3",
    "href": "ica/03-adv-ggplot-notes.html#exercise-3",
    "title": "3 Adv Data Viz",
    "section": "Exercise 3",
    "text": "Exercise 3\nIn your visualization, also display the usual temperatures (NormalLow and NormalHigh) and actual 2011 temperatures (Low and High). Your plot should look like the one below. The hex code of the color used for the usual temperatures is \"#C8B8BA\" and for the color used for actual temperatures is \"#A90248\".\n\n\nSFO observed, Average, and Record Daily Temperatures in 2011\n\n\nCodeggplot(weather) +\n  geom_linerange(\n    aes(\n      x = dateInYear,\n      ymin = RecordLow,\n      ymax = RecordHigh\n    ),\n    color = \"#ECEBE3\"\n  ) +\n  \n  geom_linerange(\n    aes(\n      x = dateInYear,\n      ymin = NormalLow,\n      ymax = NormalHigh\n    ),\n    color = \"#C8B8BA\"\n  ) +\n  \n  geom_linerange(\n    aes(\n      x = dateInYear,\n      ymin = Low,\n      ymax = High\n    ),\n    color = \"#A90248\"\n  ) +\n  \n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipFiner Control\n\n\n\nIf you‚Äôd like finer control of the width of these lines/rectangles, check out the geom_rect documentation page.",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>3 Adv Data Viz</span>"
    ]
  },
  {
    "objectID": "ica/03-adv-ggplot-notes.html#exercise-4",
    "href": "ica/03-adv-ggplot-notes.html#exercise-4",
    "title": "3 Adv Data Viz",
    "section": "Exercise 4",
    "text": "Exercise 4\nRecreate the visual demarcations of the months by adding vertical lines separating the months. Brainstorm how we might draw those vertical lines. What geom might we use? What subset of the data might we use in that geom layer to draw lines only at the month divisions?\n\nCodeggplot(weather) +\n  geom_linerange(\n    aes(x = dateInYear, ymin = RecordLow, ymax = RecordHigh),\n    color = \"#ECEBE3\"\n  ) +\n\n  geom_linerange(\n    aes(x = dateInYear, ymin = NormalLow, ymax = NormalHigh),\n    color = \"#C8B8BA\"\n  ) +\n\n  geom_linerange(\n    aes(x = dateInYear, ymin = Low, ymax = High),\n    color = \"#A90248\"\n  ) +\n\n  geom_vline(\n  data = weather |&gt; filter(Day == 1),\n  aes(xintercept = dateInYear),\n  color = \"grey70\",\n  linetype = \"dashed\"\n  ) +\n\n  theme_classic()",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>3 Adv Data Viz</span>"
    ]
  },
  {
    "objectID": "ica/03-adv-ggplot-notes.html#exercise-5",
    "href": "ica/03-adv-ggplot-notes.html#exercise-5",
    "title": "3 Adv Data Viz",
    "section": "Exercise 5",
    "text": "Exercise 5\nChange the x-axis labels so that the month names display in the center of each month‚Äôs slice of the plot.\n\n\n\n\n\n\nTipMonth Names\n\n\n\nR has built-in variables called month.abb and month.name that contain abbreviated and full month names.\n\n\n\nCodemonth_centers &lt;- weather |&gt;\n  group_by(Month) |&gt;\n  summarize(center = mean(dateInYear))\n\nggplot(weather) +\n  geom_linerange(\n    aes(x = dateInYear, ymin = RecordLow, ymax = RecordHigh),\n    color = \"#ECEBE3\"\n  ) +\n  geom_linerange(\n    aes(x = dateInYear, ymin = NormalLow, ymax = NormalHigh),\n    color = \"#C8B8BA\"\n  ) +\n  geom_linerange(\n    aes(x = dateInYear, ymin = Low, ymax = High),\n    color = \"#A90248\"\n  ) +\n  geom_vline(\n    data = weather |&gt; filter(Day == 1),\n    aes(xintercept = dateInYear),\n    linetype = \"dashed\",\n    color = \"grey70\"\n  ) +\n  scale_x_continuous(\n    breaks = month_centers$center,\n    labels = month.abb\n  ) +\n  theme_classic()\n\n\n\n\n\n\n\nTry to figuring out this new challenge using search engines and LLMs:\n\nSearch Engines. Use Google to search for possible solutions using the jargon that is most likely to return the most relevant results. Record search queries and your thought process in selecting which search results to look at first.\nLLMs. Use ChatGPT or Gemini with prompts that will most efficiently get you the desired results. Record the chat prompts used and output given. Evaluate the output. Do you fully understand the code generated? How can you tell that the generated code is correct?",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>3 Adv Data Viz</span>"
    ]
  },
  {
    "objectID": "ica/03-adv-ggplot-notes.html#exercise-6",
    "href": "ica/03-adv-ggplot-notes.html#exercise-6",
    "title": "3 Adv Data Viz",
    "section": "Exercise 6",
    "text": "Exercise 6\nCreate a precipitation plot that looks like the following. Note that\n\nThe triangles point to precipitation records‚Äìrefer to the data codebook above for the RecordP variable.\nThe numbers on the plot indicate the total precipitation for the month‚Äìsearch the hjust and vjust options to adjust the alignment of the numbers.\nThe blue and tan colors hex codes are \"#32a3d8\" and \"#ebeae2\", respectively.\n\n\n\nSFO Precipitation in 2011\n\n\nCodemonthly_totals &lt;- weather %&gt;%\n  group_by(Month) %&gt;%\n  summarize(\n    total_prec = max(CulmPrec, na.rm = TRUE),\n    center = mean(dateInYear, na.rm = TRUE)\n  )\n\n\n\nCodeggplot(weather, aes(x = dateInYear, y = CulmPrec)) +\n\n  geom_area(fill = \"#ebeae2\") +\n\n  geom_line(color = \"#32a3d8\") +\n\n  geom_point(\n    data = weather |&gt; filter(RecordP == TRUE),\n    aes(x = dateInYear, y = CulmPrec),\n    shape = 25,      # filled downward triangle\n    fill = \"black\",\n    size = 3\n  ) +\n\n  geom_text(\n    data = monthly_totals,\n    aes(x = center, y = total_prec, label = round(total_prec, 2)),\n    vjust = -0.5\n  ) +\n\n  theme_classic() +\n  labs(\n    x = \"dateInYear\",\n    y = \"CulmPrec\"\n  )",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>3 Adv Data Viz</span>"
    ]
  },
  {
    "objectID": "ica/03-adv-ggplot-notes.html#done",
    "href": "ica/03-adv-ggplot-notes.html#done",
    "title": "3 Adv Data Viz",
    "section": "Done!",
    "text": "Done!\n\nCheck the ICA Instructions for how to (a) push your code to GitHub and (b) update your portfolio website",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>3 Adv Data Viz</span>"
    ]
  },
  {
    "objectID": "ica/03-adv-ggplot-notes.html#footnotes",
    "href": "ica/03-adv-ggplot-notes.html#footnotes",
    "title": "3 Adv Data Viz",
    "section": "",
    "text": "The exercise in this lesson are inspired by an assignment from the Concepts in Computing with Data course at UC Berkeley taught by Dr.¬†Deborah Nolan.‚Ü©Ô∏é",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>3 Adv Data Viz</span>"
    ]
  },
  {
    "objectID": "ica/04_adv_maps/code/04-adv-maps-1-notes.html",
    "href": "ica/04_adv_maps/code/04-adv-maps-1-notes.html",
    "title": "4 Adv Spatial Viz P1",
    "section": "",
    "text": "üß© Learning Goals\nBy the end of this lesson, you should be able to:",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>4 Adv Spatial Viz P1</span>"
    ]
  },
  {
    "objectID": "ica/04_adv_maps/code/04-adv-maps-1-notes.html#learning-goals",
    "href": "ica/04_adv_maps/code/04-adv-maps-1-notes.html#learning-goals",
    "title": "4 Adv Spatial Viz P1",
    "section": "",
    "text": "Understand the basics of a CRS (coordinate reference system)\nUnderstand and recognize different spatial file types and data types in R\nImplement some of the basic plotting with the sf package\nUnderstand foundation ideas in working with spatial data (aggregating spatial point data to a spatial region, joining spatial data sets)",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>4 Adv Spatial Viz P1</span>"
    ]
  },
  {
    "objectID": "ica/04_adv_maps/code/04-adv-maps-1-notes.html#additional-resources",
    "href": "ica/04_adv_maps/code/04-adv-maps-1-notes.html#additional-resources",
    "title": "4 Adv Spatial Viz P1",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nSpatial Data Science with Applications in R book: web\n\nSpatial Data Science with R and terra Resources: web\n\nLeaflet in R Package: web\n\nCRAN task view on spatial analysis: web",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>4 Adv Spatial Viz P1</span>"
    ]
  },
  {
    "objectID": "ica/04_adv_maps/code/04-adv-maps-1-notes.html#setup",
    "href": "ica/04_adv_maps/code/04-adv-maps-1-notes.html#setup",
    "title": "4 Adv Spatial Viz P1",
    "section": "Setup",
    "text": "Setup\nFor this activity, create the following directory structure in your portfolio repository under src/ica folder:\nportfolio\n‚îî‚îÄ¬†src\n¬†¬†¬†‚îî‚îÄ¬†ica\n¬†¬†¬†¬†¬†¬†‚îî‚îÄ¬†04_adv_maps\n¬†¬†¬†¬†¬†¬†¬†¬†¬†‚îú‚îÄ¬†code\n¬†¬†¬†¬†¬†¬†¬†¬†¬†‚îÇ¬†¬†‚îî‚îÄ¬†04-adv-maps-1-notes.qmd\n¬†¬†¬†¬†¬†¬†¬†¬†¬†‚îú‚îÄ¬†data\n¬†¬†¬†¬†¬†¬†¬†¬†¬†‚îÇ¬†¬†‚îî‚îÄ¬†...  ‚Üê saving data here during this activity\n¬†¬†¬†¬†¬†¬†¬†¬†¬†‚îî‚îÄ¬†figures\n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†‚îî‚îÄ¬†...  ‚Üê saving created maps here during this activity\nFirst load required packages.\n\nCode# install.packages(\n#   \"USAboundariesData\",\n#   repos = \"https://ropensci.r-universe.dev\",\n#   type = \"source\"\n# )\nlibrary(USAboundariesData)\n\nloadNamespace(\"USAboundariesData\")\n\n&lt;environment: namespace:USAboundariesData&gt;\n\nCode#Install these packages first\n\n# install.packages(c(\"sf\",\"elevatr\",\"terra\",\"stars\",\"tidycensus\"))\n# install.packages('devtools')\n# devtools::install_github(\"ropensci/USAboundaries\")\n# install.packages(\"USAboundariesData\", repos = \"https://ropensci.r-universe.dev\", type = \"source\")\n\n\nlibrary(tidyverse)\nlibrary(sf) # tools for working with spatial vector data (GIS functionality, mapping)\nlibrary(elevatr) # access to raster elevation maps\nlibrary(terra)\nlibrary(stars)\nlibrary(tidycensus) # spatial data for the US with census information\nlibrary(USAboundaries) # access to boundaries for US states, counties, zip codes, and congressional districts",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>4 Adv Spatial Viz P1</span>"
    ]
  },
  {
    "objectID": "ica/04_adv_maps/code/04-adv-maps-1-notes.html#spatial-data-in-r",
    "href": "ica/04_adv_maps/code/04-adv-maps-1-notes.html#spatial-data-in-r",
    "title": "4 Adv Spatial Viz P1",
    "section": "Spatial Data in R",
    "text": "Spatial Data in R\nSee Spatial Data Appendix for basics of CRS and spatial data types.\nDownload Shapefiles\n\nNavigate to the following URLs to download the spatial data files we‚Äôll be using in this activity. Put these files in the data folder of your 04_adv_maps folder.\n\n\nMN cities: https://gisdata.mn.gov/dataset/loc-pop-centers\n\nFile type: shapefile (.shp)\nFile name: shp_loc_pop_centers.zip (Unzip this after downloading.)\n\n\nMN water: https://gisdata.mn.gov/dataset/us-mn-state-metc-water-lakes-rivers\n\nFile type: shapefile (.shp)\nFile name: shp_water_lakes_rivers.zip (Unzip this after downloading.)\n\n\nRead in Files\n\nRead in the MN cities and MN water shapefiles by entering the correct relative paths in st_read(). Tab completion will be very helpful here: type part of a directory or file name and hit tab to autocomplete or bring up a dropdown of options.\n\n\n\nCode# The sf package comes with a North Carolina shapefile:\nnc &lt;- st_read(system.file(\"shape/nc.shp\", package = \"sf\"))\n\nReading layer `nc' from data source \n  `/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/sf/shape/nc.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 100 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\nGeodetic CRS:  NAD27\n\nCode# Read in shapefiles just downloaded\nmn_cities &lt;- st_read(\"../data/shp_loc_pop_centers/city_and_township_population_centers.shp\")\n\nReading layer `city_and_township_population_centers' from data source \n  `/Users/mariaantonova/Documents/GitHub/portfolio-mashaantonova1/ica/04_adv_maps/data/shp_loc_pop_centers/city_and_township_population_centers.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1081 features and 8 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 190832.6 ymin: 4816672 xmax: 747463.4 ymax: 5468045\nProjected CRS: NAD83 / UTM zone 15N\n\nCodemn_water &lt;- st_read(\"../data/shp_water_lakes_rivers/LakesAndRivers.shp\")\n\nReading layer `LakesAndRivers' from data source \n  `/Users/mariaantonova/Documents/GitHub/portfolio-mashaantonova1/ica/04_adv_maps/data/shp_water_lakes_rivers/LakesAndRivers.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2313 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 419538.6 ymin: 4922700 xmax: 522665 ymax: 5029945\nProjected CRS: NAD83 / UTM zone 15N\n\n\nThe sf package reads in spatial data in data.frame-like format. Using the class() function we can check the class (type) of object that we just read in. Note the presence of the ‚Äúsf‚Äù and ‚Äúdata.frame‚Äù classes:\n\nCodeclass(nc)\n\n[1] \"sf\"         \"data.frame\"\n\nCodeclass(mn_cities)\n\n[1] \"sf\"         \"data.frame\"\n\nCodeclass(mn_water)\n\n[1] \"sf\"         \"data.frame\"\n\n\nWhen we read in spatial objects, it is useful to check what CRS underlies the data. We can do that with st_crs() from the sf package:\n\nCodest_crs(nc)\n\nCoordinate Reference System:\n  User input: NAD27 \n  wkt:\nGEOGCRS[\"NAD27\",\n    DATUM[\"North American Datum 1927\",\n        ELLIPSOID[\"Clarke 1866\",6378206.4,294.978698213898,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4267]]\n\n\nWe can treat sf objects similarly to ordinary datasets when using ggplot2 to make spatial visualizations:\n\nCodeggplot(nc) +\n    geom_sf() +\n    theme_classic() +\n    labs(title = \"NAD27\")\n\n\n\n\n\n\n\nChange CRS\n\nLet‚Äôs explore how changing the CRS changes the map. The st_transform() function in sf re-expresses a spatial object using a user-supplied CRS. The crs argument takes a string descriptor of the CRS. We can find these descriptors via https://epsg.io. In the example below, I searched for ‚ÄúSouth Carolina‚Äù.\n\n\nCodenc_transformed &lt;- nc |&gt; st_transform(crs = \"EPSG:32133\")\nst_crs(nc_transformed)\n\nCoordinate Reference System:\n  User input: EPSG:32133 \n  wkt:\nPROJCRS[\"NAD83 / South Carolina\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"SPCS83 South Carolina zone (meter)\",\n        METHOD[\"Lambert Conic Conformal (2SP)\",\n            ID[\"EPSG\",9802]],\n        PARAMETER[\"Latitude of false origin\",31.8333333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8821]],\n        PARAMETER[\"Longitude of false origin\",-81,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8822]],\n        PARAMETER[\"Latitude of 1st standard parallel\",34.8333333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8823]],\n        PARAMETER[\"Latitude of 2nd standard parallel\",32.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8824]],\n        PARAMETER[\"Easting at false origin\",609600,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8826]],\n        PARAMETER[\"Northing at false origin\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8827]]],\n    CS[Cartesian,2],\n        AXIS[\"easting (X)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"northing (Y)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"United States (USA) - South Carolina - counties of Abbeville; Aiken; Allendale; Anderson; Bamberg; Barnwell; Beaufort; Berkeley; Calhoun; Charleston; Cherokee; Chester; Chesterfield; Clarendon; Colleton; Darlington; Dillon; Dorchester; Edgefield; Fairfield; Florence; Georgetown; Greenville; Greenwood; Hampton; Horry; Jasper; Kershaw; Lancaster; Laurens; Lee; Lexington; Marion; Marlboro; McCormick; Newberry; Oconee; Orangeburg; Pickens; Richland; Saluda; Spartanburg; Sumter; Union; Williamsburg; York.\"],\n        BBOX[32.05,-83.36,35.21,-78.52]],\n    ID[\"EPSG\",32133]]\n\nCodeggplot(nc_transformed) +\n    geom_sf() +\n    theme_classic()\n\n\n\n\n\n\n\nThe goal is to use https://epsg.io to find two CRSs that result in a North Carolina map that is noticeably different from the original in the NAD27 CRS.\nTake a look at the function below that re-maps a spatial object using a new CRS.\n\nRead through the function to get a sense for how this code works.\n\nspatial_obj and new_crs are called arguments (function inputs).\n\nAdd one more argument called title to this function. Use this input to set the plot title.\n\n\nUse your function to make two new maps using your chosen CRSs.\n\n\nCodenc &lt;- st_read(system.file(\"shape/nc.shp\", package = \"sf\"))\n\nReading layer `nc' from data source \n  `/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/sf/shape/nc.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 100 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\nGeodetic CRS:  NAD27\n\nCodetransform_and_plot &lt;- function(spatial_obj, new_crs, title) {\n    spatial_obj |&gt; \n        st_transform(crs = new_crs) |&gt; \n        ggplot() +\n            geom_sf() +\n            labs(title = title) +\n            theme_classic()\n}\n\nggplot(nc) +\n    geom_sf() +\n    theme_classic() +\n    labs(title = \"NAD27 (Original)\")\n\n\n\n\n\n\nCodetransform_and_plot(nc, new_crs = \"EPSG:3112\", title = \"Australia (GDA94)\")\n\n\n\n\n\n\nCodetransform_and_plot(nc, new_crs = \"EPSG:20353\", title = \"Australia (Queensland, South, West)\")\n\n\n\n\n\n\nCodetransform_and_plot(nc, new_crs = \"EPSG:5940\", title = \"Russia\")\n\n\n\n\n\n\n\nVerify your understanding: If you had point location data that was not in the NAD27 CRS, what would you expect about the accuracy of how they would be overlaid on the original North Carolina map?",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>4 Adv Spatial Viz P1</span>"
    ]
  },
  {
    "objectID": "ica/04_adv_maps/code/04-adv-maps-1-notes.html#mn-map-with-multiple-layers",
    "href": "ica/04_adv_maps/code/04-adv-maps-1-notes.html#mn-map-with-multiple-layers",
    "title": "4 Adv Spatial Viz P1",
    "section": "MN Map with Multiple Layers",
    "text": "MN Map with Multiple Layers\nGoal: create a map of MN with different layers of information (city point locations, county polygon boundaries, rivers as lines and polygons, and a raster elevation map).\nGet County Boundaries\n\nWe‚Äôve already read in city location and water information from external shapefiles. We can access county boundaries with the us_counties() function in the USAboundaries package.\n\n\nCode# Load country boundaries data as sf object\nmn_counties &lt;- USAboundaries::us_counties(resolution = \"high\", states = \"Minnesota\")\n\n# Take care of duplicate column names (there are two identical \"state_name\" columns)\nnames_counties &lt;- names(mn_counties)\nnames(mn_counties)[names_counties == \"state_name\"] &lt;- c(\"state_name1\", \"state_name2\")\n\n\nUnifying CRSs Across Different Spatial Datasets\n\nWe first need to ensure that the CRS is the same for all spatial datasets.\n\n\nCheck the CRS for the mn_cities, mn_water, and mn_counties datasets.\nIf the datasets don‚Äôt all have the same CRS, use st_transform() to update the datasets to have the same CRS as mn_cities. You can use crs = st_crs(mn_cities) within st_transform().\n\n\nCode# Check CRSs\nst_crs(mn_cities)\n\nCoordinate Reference System:\n  User input: NAD83 / UTM zone 15N \n  wkt:\nPROJCRS[\"NAD83 / UTM zone 15N\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"UTM zone 15N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-93,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    ID[\"EPSG\",26915]]\n\nCodest_crs(mn_water)\n\nCoordinate Reference System:\n  User input: NAD83 / UTM zone 15N \n  wkt:\nPROJCRS[\"NAD83 / UTM zone 15N\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"UTM zone 15N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-93,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    ID[\"EPSG\",26915]]\n\nCodest_crs(mn_counties)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        MEMBER[\"World Geodetic System 1984 (G2296)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\nCode# Transform the CRS of county data to the more local CRS of the cities\nmn_counties &lt;- mn_counties |&gt;\n    st_transform(crs = st_crs(mn_cities))\n\n# Check the new CRS for mn_counties\nst_crs(mn_counties)\n\nCoordinate Reference System:\n  User input: NAD83 / UTM zone 15N \n  wkt:\nPROJCRS[\"NAD83 / UTM zone 15N\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"UTM zone 15N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-93,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    ID[\"EPSG\",26915]]\n\n\nCounties + Cities\n\nCreate a map where city locations are overlaid on a map of county boundaries.\n\n\nYou will need to call geom_sf() twice.\nMake the map background white.\nInstall the ggthemes package, and add the following layer to use a clean map theme: + ggthemes::theme_map()\n\n\n\nCodeggplot() +\n    geom_sf(data = mn_counties, fill = \"white\") + \n    geom_sf(data = mn_cities, size = 0.5) +\n    ggthemes::theme_map()\n\n\n\n\n\n\n\nCustomize Colors\n\nWe can use traditional ggplot2 aesthetics (e.g., fill, color) to display location specific attributes. Below we only plot large cities, and we color and size cities according to their population.\n\n\nCodeggplot() +\n    geom_sf(data = mn_counties, fill = \"white\") + \n    geom_sf(data = mn_cities |&gt; filter(Population &gt;= 10000), mapping = aes(color = Population, size = Population)) + # cities layer\n    scale_color_viridis_c() + # continuous (gradient) color scale\n    labs(title = \"Minnesota Cities with Population &gt;= 10,000\") + \n    ggthemes::theme_map() +\n    theme(legend.position = \"bottom\") # move legend\n\n\n\n\n\n\n\nLook up the scale_color_viridis_c() documentation via the ggplot2 reference.\n\nRead the function description at the top. What is the advantage of using this function for making color palettes?\nLook through the examples section. What is the difference between the _d(), _c(), and _b() variants of this function?\n\nThe viridis color scale results in plots that can be interpreted analogously whether in color or black and white and is color-blind friendly.\n\nThe _d() variant is used when color is mapped to a discrete (categorical) variable.\nThe _c() variant is used when color is mapped to a continuous variable.\nThe _b() variant is used when color is mapped to a continuous variable but when we want that continuous variable to be binned so that there is a small set of colors.\nAdding Elevation Raster Data\nWhere are large cities located? Is there some relationship to local geography/terrain?\n\nTo investigate these questions, we can obtain elevation data to include on the map using the elevatr package. We encounter two new functions here‚Äîwe can look up their documentation to make sense of the code by entering the following in the Console:\n\n\n?elevatr::get_elev_raster\n?terra::as.data.frame\n\n\nCodeelevation &lt;- elevatr::get_elev_raster(mn_counties, z = 5, clip = \"bbox\")\nraster::crs(elevation) &lt;- sf::st_crs(mn_counties)\n\n# Convert to data frame for plotting\nelev_df &lt;- elevation |&gt; terra::as.data.frame(xy = TRUE)\ncolnames(elev_df) &lt;- c(\"x\", \"y\", \"elevation\")\n\n\nBuild on our existing map by adding a raster layer for elevation as the background.\n\nLook up the documentation for geom_raster() to plot the elevation data from elev_df. This will be the first layer of the plot.\nLook at the documentation for scale_fill_gradient() to add the following elevation color scale: \"darkgreen\" represents the lowest elevations, and \"white\" represents the highest elevations.\nAdd in the layers from the map above to show the largest cities and the county outlines. To remove a background color, use fill = NA.\n\n\nCodeggplot() +\n    geom_raster(data = elev_df, aes(x = x, y = y, fill = elevation)) +\n    scale_fill_gradient(low = \"darkgreen\", high = \"white\", guide = FALSE) +\n    geom_sf(data = mn_counties, fill = NA, color = \"black\") + \n    geom_sf(data = mn_cities |&gt; filter(Population &gt;= 10000), mapping = aes(color = Population, size = Population))+\n    scale_color_viridis_c() + \n    labs(title = \"Minnesota Cities with Population &gt;= 10,000\") + \n    ggthemes::theme_map() +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nZoom in to Twin Cities and Add Water\n\nThe bulk of the interesting information in this map is in the Twin Cities area. Let‚Äôs zoom in to this area.\n\n\nWe can use the st_bbox() function to get the bounding box for a spatial object‚Äîwe do this after filtering to the 7 counties in the Twin Cities.\nWe then use st_crop() to trim a spatial object to a given bounding box.\n\n\nCodeseven_countyarea &lt;- mn_counties |&gt;\n    filter(name %in% c(\"Anoka\", \"Hennepin\", \"Ramsey\", \"Dakota\", \"Carver\", \"Washington\", \"Scott\")) |&gt; \n    st_bbox()\nseven_countyarea\n\n     xmin      ymin      xmax      ymax \n 419967.1 4924212.8  521254.8 5029157.4 \n\nCodeelevation &lt;- elevatr::get_elev_raster(mn_counties |&gt; st_crop(seven_countyarea), z = 9, clip = \"bbox\")\nraster::crs(elevation) &lt;- sf::st_crs(mn_counties)\n\n# Convert to data frame for plotting\nelev_df &lt;- elevation |&gt; terra::as.data.frame(xy = TRUE)\ncolnames(elev_df) &lt;- c(\"x\", \"y\", \"elevation\")\n\n\nIn the plot below, we add a layer for water information and a coord_sf() layer to restrict the x and y-axis limits to the Twin Cities bounding box. (Without this layer, the map would zoom back out to show all counties and bodies of water).\n\nCodepng(\"../figures/tc_map_zoom.png\", width = 800, height = 500)\nggplot() +\n    geom_raster(data = elev_df, aes(x = x, y = y, fill = elevation)) + \n    geom_sf(data = mn_counties, fill = NA, color = \"black\") + # county boundary layer\n    geom_sf(data = mn_water, fill = \"lightsteelblue1\", color = \"lightsteelblue1\") + # NEW: river/lake layer\n    geom_sf(data = mn_cities |&gt; filter(Population &gt;= 10000), mapping = aes(color = Population, size = Population)) + # cities layer\n    scale_color_viridis_c(option = \"magma\") + # continuous (gradient) color scale\n    scale_fill_gradient(low = \"darkgreen\", high = \"white\") + # continuous (gradient) fill scale\n    coord_sf(xlim = seven_countyarea[c(\"xmin\", \"xmax\")], ylim = seven_countyarea[c(\"ymin\", \"ymax\")]) + # NEW: crop map to Twin Cities bounding box\n    labs(title = \"Twin Cities with Population &gt;= 10,000\") + \n    ggthemes::theme_map() +\n    theme(legend.position = \"none\") # remove legend\ndev.off()\n\nquartz_off_screen \n                2 \n\n\nLet‚Äôs add to the above code chunk to save the map above to an image file called tc_map_zoom.png in the figures folder. The code example below shows a general template for saving a plot to file. Choose a reasonable width and height. (There are also jpeg() and pdf() functions for writing images.)\n\nCode# png(\"../figures/tc_map_zoom.png\", width = 800, height = 500)\n# # Code for creating plot\n# dev.off()",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>4 Adv Spatial Viz P1</span>"
    ]
  },
  {
    "objectID": "ica/04_adv_maps/code/04-adv-maps-1-notes.html#going-beyond---twin-cities-map-with-leaflet",
    "href": "ica/04_adv_maps/code/04-adv-maps-1-notes.html#going-beyond---twin-cities-map-with-leaflet",
    "title": "4 Adv Spatial Viz P1",
    "section": "Going Beyond - Twin Cities Map with leaflet\n",
    "text": "Going Beyond - Twin Cities Map with leaflet\n\nBelow we show how to make the MN counties map in the leaflet package.\n\nCodelibrary(leaflet)\n\nmn_counties_leaf &lt;- mn_counties |&gt; st_transform(4326) # Leaflet expects this CRS for vectors\nmn_cities_leaf &lt;- mn_cities |&gt; st_transform(4326)\n\ncities_per_county &lt;- st_join(mn_cities_leaf, mn_counties_leaf) |&gt;\n    st_drop_geometry() |&gt; # removes geometry - makes the following calculation more efficient\n    count(name) \n\nmn_counties_leaf |&gt; \n    filter(name %in% c(\"Anoka\", \"Hennepin\", \"Ramsey\", \"Dakota\", \"Carver\", \"Washington\", \"Scott\")) |&gt;\n    left_join(cities_per_county) |&gt;\n    leaflet() |&gt; \n    addProviderTiles(\"CartoDB.Positron\") |&gt; \n    addPolygons(\n        color = \"#444444\", weight = 1, smoothFactor = 0.5, opacity = 1.0,\n        fillOpacity = 0.5, fillColor = ~colorQuantile(\"YlOrRd\", n)(n),\n        highlightOptions = highlightOptions(color = \"white\", weight = 2, bringToFront = TRUE)) |&gt;\n    addCircles(data = mn_cities_leaf |&gt; filter(County %in% paste(c(\"Anoka\", \"Hennepin\", \"Ramsey\", \"Dakota\", \"Carver\", \"Washington\", \"Scott\"), \"County\")), color = \"#444444\")",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>4 Adv Spatial Viz P1</span>"
    ]
  },
  {
    "objectID": "ica/04_adv_maps/code/04-adv-maps-1-notes.html#done",
    "href": "ica/04_adv_maps/code/04-adv-maps-1-notes.html#done",
    "title": "4 Adv Spatial Viz P1",
    "section": "Done!",
    "text": "Done!\n\nCheck the ICA Instructions for how to (a) push your code to GitHub and (b) update your portfolio website",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>4 Adv Spatial Viz P1</span>"
    ]
  },
  {
    "objectID": "ica/06-wrangling-1-notes.html",
    "href": "ica/06-wrangling-1-notes.html",
    "title": "6 Adv Data wrangling I",
    "section": "",
    "text": "üß© Learning Goals\nBy the end of this lesson, you should be able to:",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>6 Adv Data wrangling I</span>"
    ]
  },
  {
    "objectID": "ica/06-wrangling-1-notes.html#learning-goals",
    "href": "ica/06-wrangling-1-notes.html#learning-goals",
    "title": "6 Adv Data wrangling I",
    "section": "",
    "text": "Determine the class of a given object and identify concerns to be wary of when manipulating an object of that class (numerics, logicals, factors, dates, strings, data.frames)\nExplain what vector recycling is, when it can be a problem, and how to avoid those problems\nUse a variety of functions to wrangle numerical and logical data\nExtract date-time information using the lubridate package\nUse the forcats package to wrangle factor data",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>6 Adv Data wrangling I</span>"
    ]
  },
  {
    "objectID": "ica/06-wrangling-1-notes.html#helpful-cheatsheets",
    "href": "ica/06-wrangling-1-notes.html#helpful-cheatsheets",
    "title": "6 Adv Data wrangling I",
    "section": "Helpful Cheatsheets",
    "text": "Helpful Cheatsheets\nRStudio (Posit) maintains a collection of wonderful cheatsheets. The following will be helpful:\n\nData transformation with dplyr\nDates and times with lubridate\nFactors with forcats\n\nData Wrangling Verbs (from Stat/Comp 112)\n\n\nmutate(): creates/changes columns/elements in a data frame/tibble\n\nselect(): keeps subset of columns/elements in a data frame/tibble\n\nfilter(): keeps subsets of rows in a data frame/tibble\n\narrange(): sorts rows in a data frame/tibble\n\ngroup_by(): internally groups rows in data frame/tibble by values in 1 or more columsn/elements\n\nsummarize(): collapses/combines information across rows using functions such as n(), sum(), mean(), min(), max(), median(), sd()\n\n\ncount(): shortcut for group_by() |&gt; summarize(n = n())\n\n\nleft_join(): mutating join of two data frames/tibbles keeping all rows in left data frame\n\nfull_join(): mutating join of two data frames/tibbles keeping all rows in both data frames\n\ninner_join(): mutating join of two data frames/tibbles keeping rows in left data frame that find match in right\n\nsemi_join(): filtering join of two data frames/tibbles keeping rows in left data frame that find match in right\n\nanti_join(): filtering join of two data frames/tibbles keeping rows in left data frame that do not find match in right\n\npivot_wider(): rearrange values from two columns to many(one column becomes the names of new variables, one column becomes the values of the new variables)\n\npivot_longer(): rearrange values from many columns to two (the names of the columns go to one new variable, the values of the columns go to a second new variable)",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>6 Adv Data wrangling I</span>"
    ]
  },
  {
    "objectID": "ica/06-wrangling-1-notes.html#vectors",
    "href": "ica/06-wrangling-1-notes.html#vectors",
    "title": "6 Adv Data wrangling I",
    "section": "Vectors",
    "text": "Vectors\nAn atomic vector is a storage container in R where all elements in the container are of the same type. The types that are relevant to data science are:\n\n\nlogical (also known as boolean)\nnumbers\n\ninteger\n\nnumeric floating point (also known as double)\n\n\n\ncharacter string\n\nDate and date-time (saved as POSIXct)\nfactor\n\nFunction documentation will refer to vectors frequently.\nSee examples below:\n\n\nggplot2::scale_x_continuous()\n\n\nbreaks: A numeric vector of positions\n\nlabels: A character vector giving labels (must be same length as breaks)\n\n\n\nshiny::sliderInput()\n\n\nvalue: The initial value of the slider [‚Ä¶] A length one vector will create a regular slider; a length two vector will create a double-ended range slider.\n\n\n\nWhen you need a vector, you can create one manually using\n\n\nc(): the combine function\n\nOr you can create one based on available data using\n\n\ndataset |&gt; mutate(newvar = variable &gt; 5) |&gt; pull(newvar): taking one column out of a dataset\n\ndataset |&gt; pull(variable) |&gt; unique(): taking one column out of a dataset and finding unique values\n\n\nCodec(\"Fair\", \"Good\", \"Very Good\", \"Premium\", \"Ideal\")\n\n[1] \"Fair\"      \"Good\"      \"Very Good\" \"Premium\"   \"Ideal\"    \n\nCodediamonds |&gt; pull(cut) |&gt; unique()\n\n[1] Ideal     Premium   Good      Very Good Fair     \nLevels: Fair &lt; Good &lt; Very Good &lt; Premium &lt; Ideal",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>6 Adv Data wrangling I</span>"
    ]
  },
  {
    "objectID": "ica/06-wrangling-1-notes.html#logicals",
    "href": "ica/06-wrangling-1-notes.html#logicals",
    "title": "6 Adv Data wrangling I",
    "section": "Logicals",
    "text": "Logicals\nNotes\nWhat does a logical vector look like?\n\nCodex &lt;- c(TRUE, FALSE, NA)\nx\n\n[1]  TRUE FALSE    NA\n\nCodeclass(x)\n\n[1] \"logical\"\n\n\nYou will often create logical vectors with comparison operators: &gt;, &lt;, &lt;=, &gt;=, ==, !=.\n\nCodex &lt;- c(1, 2, 9, 12)\nx &lt; 2\n\n[1]  TRUE FALSE FALSE FALSE\n\nCodex &lt;= 2\n\n[1]  TRUE  TRUE FALSE FALSE\n\nCodex &gt; 9\n\n[1] FALSE FALSE FALSE  TRUE\n\nCodex &gt;= 9\n\n[1] FALSE FALSE  TRUE  TRUE\n\nCodex == 12\n\n[1] FALSE FALSE FALSE  TRUE\n\nCodex != 12\n\n[1]  TRUE  TRUE  TRUE FALSE\n\n\nWhen you want to check for set containment, the %in% operator is the correct way to do this (as opposed to ==).\n\nCodex &lt;- c(1, 2, 9, 4)\nx == c(1, 2, 4)\n\nWarning in x == c(1, 2, 4): longer object length is not a multiple of shorter\nobject length\n\n\n[1]  TRUE  TRUE FALSE FALSE\n\nCodex %in% c(1, 2, 4)\n\n[1]  TRUE  TRUE FALSE  TRUE\n\n\nThe Warning: longer object length is not a multiple of shorter object length is a manifestation of vector recycling.\nIn R, if two vectors are being combined or compared, the shorter one will be repeated to match the length of the longer one‚Äìeven if longer object length isn‚Äôt a multiple of the shorter object length. We can see the exact recycling that happens below:\n\nCodex &lt;- c(1, 2, 9, 4)\nx == c(1, 2, 4)\n\n[1]  TRUE  TRUE FALSE FALSE\n\nCodex == c(1, 2, 4, 1) # This line demonstrates the recycling that happens on the previous line\n\n[1]  TRUE  TRUE FALSE FALSE\n\n\nLogical vectors can also be created with functions. is.na() is one useful example:\n\nCodex &lt;- c(1, 4, 9, NA)\nx == NA\n\n[1] NA NA NA NA\n\nCodeis.na(x)\n\n[1] FALSE FALSE FALSE  TRUE\n\n\nWe can negate a logical object with !. We can combine logical objects with & (and) and | (or).\n\nCodex &lt;- c(1, 2, 4, 9)\nx &gt; 1 & x &lt; 5\n\n[1] FALSE  TRUE  TRUE FALSE\n\nCode!(x &gt; 1 & x &lt; 5)\n\n[1]  TRUE FALSE FALSE  TRUE\n\nCodex &lt; 2 | x &gt; 8\n\n[1]  TRUE FALSE FALSE  TRUE\n\n\nWe can summarize logical vectors with:\n\n\nany(): Are ANY of the values TRUE?\n\nall(): Are ALL of the values TRUE?\n\nsum(): How many of the values are TRUE?\n\nmean(): What fraction of the values are TRUE?\n\n\nCodex &lt;- c(1, 2, 4, 9)\nany(x == 1)\n\n[1] TRUE\n\nCodeall(x &lt; 10)\n\n[1] TRUE\n\nCodesum(x == 1)\n\n[1] 1\n\nCodemean(x == 1)\n\n[1] 0.25\n\n\nif_else() and case_when() are functions that allow you to return values depending on the value of a logical vector. You‚Äôll explore the documentation for these in the following exercises.\n\n\n\n\n\n\nNote: ifelse() (from base R) and if_else() (from tidyverse) are different functions. We prefer if_else() for many reasons (examples below).\n\nNoisy to make sure you catch issues/bugs\nCan explicitly handle missing values\nKeeps dates as dates\n\n\nExamples\n\nCodex &lt;- c(-1, -2, 4, 9, NA)\n\nifelse(x &gt; 0, 'positive', 'negative')\n\n[1] \"negative\" \"negative\" \"positive\" \"positive\" NA        \n\nCodeif_else(x &gt; 0, 'positive', 'negative')\n\n[1] \"negative\" \"negative\" \"positive\" \"positive\" NA        \n\nCodeifelse(x &gt; 0, 1, 'negative') # Bad: doesn't complain with combo of data types\n\n[1] \"negative\" \"negative\" \"1\"        \"1\"        NA        \n\nCodeif_else(x &gt; 0, 1, 'negative') # Good:noisy to make sure you catch issues\n\nError in `if_else()`:\n! Can't combine `true` &lt;double&gt; and `false` &lt;character&gt;.\n\nCodeif_else(x &gt; 0, 'positive', 'negative', missing = 'missing') # Good: can explicitly handle NA\n\n[1] \"negative\" \"negative\" \"positive\" \"positive\" \"missing\" \n\nCodefun_dates &lt;- mdy('1-1-2025') + 0:365\nifelse(fun_dates &lt; today(), fun_dates + years(), fun_dates) # Bad: converts dates to integers\n\n  [1] 20454 20455 20456 20457 20458 20459 20460 20461 20462 20463 20464 20465\n [13] 20466 20467 20468 20469 20470 20471 20472 20473 20474 20475 20476 20477\n [25] 20478 20479 20480 20481 20482 20483 20484 20485 20486 20487 20488 20489\n [37] 20490 20491 20492 20493 20494 20495 20496 20497 20498 20499 20500 20501\n [49] 20502 20503 20504 20505 20506 20507 20508 20509 20510 20511 20512 20513\n [61] 20514 20515 20516 20517 20518 20519 20520 20521 20522 20523 20524 20525\n [73] 20526 20527 20528 20529 20530 20531 20532 20533 20534 20535 20536 20537\n [85] 20538 20539 20540 20541 20542 20543 20544 20545 20546 20547 20548 20549\n [97] 20550 20551 20552 20553 20554 20555 20556 20557 20558 20559 20560 20561\n[109] 20562 20563 20564 20565 20566 20567 20568 20569 20570 20571 20572 20573\n[121] 20574 20575 20576 20577 20578 20579 20580 20581 20582 20583 20584 20585\n[133] 20586 20587 20588 20589 20590 20591 20592 20593 20594 20595 20596 20597\n[145] 20598 20599 20600 20601 20602 20603 20604 20605 20606 20607 20608 20609\n[157] 20610 20611 20612 20613 20614 20615 20616 20617 20618 20619 20620 20621\n[169] 20622 20623 20624 20625 20626 20627 20628 20629 20630 20631 20632 20633\n[181] 20634 20635 20636 20637 20638 20639 20640 20641 20642 20643 20644 20645\n[193] 20646 20647 20648 20649 20650 20651 20652 20653 20654 20655 20656 20657\n[205] 20658 20659 20660 20661 20662 20663 20664 20665 20666 20667 20668 20669\n[217] 20670 20671 20672 20673 20674 20675 20676 20677 20678 20679 20680 20681\n[229] 20682 20683 20684 20685 20686 20687 20688 20689 20690 20691 20692 20693\n[241] 20694 20695 20696 20697 20698 20699 20700 20701 20702 20703 20704 20705\n[253] 20706 20707 20708 20709 20710 20711 20712 20713 20714 20715 20716 20717\n[265] 20718 20719 20720 20721 20722 20723 20724 20725 20726 20727 20728 20729\n[277] 20730 20731 20732 20733 20734 20735 20736 20737 20738 20739 20740 20741\n[289] 20742 20743 20744 20745 20746 20747 20748 20749 20750 20751 20752 20753\n[301] 20754 20755 20756 20757 20758 20759 20760 20761 20762 20763 20764 20765\n[313] 20766 20767 20768 20769 20770 20771 20772 20773 20774 20775 20776 20777\n[325] 20778 20779 20780 20781 20782 20783 20784 20785 20786 20787 20788 20789\n[337] 20790 20791 20792 20793 20794 20795 20796 20797 20798 20799 20800 20801\n[349] 20802 20803 20804 20805 20806 20807 20808 20809 20810 20811 20812 20813\n[361] 20814 20815 20816 20817 20818 20819\n\nCodeif_else(fun_dates &lt; today(), fun_dates + years(), fun_dates) # Good: keeps dates as dates\n\n  [1] \"2026-01-01\" \"2026-01-02\" \"2026-01-03\" \"2026-01-04\" \"2026-01-05\"\n  [6] \"2026-01-06\" \"2026-01-07\" \"2026-01-08\" \"2026-01-09\" \"2026-01-10\"\n [11] \"2026-01-11\" \"2026-01-12\" \"2026-01-13\" \"2026-01-14\" \"2026-01-15\"\n [16] \"2026-01-16\" \"2026-01-17\" \"2026-01-18\" \"2026-01-19\" \"2026-01-20\"\n [21] \"2026-01-21\" \"2026-01-22\" \"2026-01-23\" \"2026-01-24\" \"2026-01-25\"\n [26] \"2026-01-26\" \"2026-01-27\" \"2026-01-28\" \"2026-01-29\" \"2026-01-30\"\n [31] \"2026-01-31\" \"2026-02-01\" \"2026-02-02\" \"2026-02-03\" \"2026-02-04\"\n [36] \"2026-02-05\" \"2026-02-06\" \"2026-02-07\" \"2026-02-08\" \"2026-02-09\"\n [41] \"2026-02-10\" \"2026-02-11\" \"2026-02-12\" \"2026-02-13\" \"2026-02-14\"\n [46] \"2026-02-15\" \"2026-02-16\" \"2026-02-17\" \"2026-02-18\" \"2026-02-19\"\n [51] \"2026-02-20\" \"2026-02-21\" \"2026-02-22\" \"2026-02-23\" \"2026-02-24\"\n [56] \"2026-02-25\" \"2026-02-26\" \"2026-02-27\" \"2026-02-28\" \"2026-03-01\"\n [61] \"2026-03-02\" \"2026-03-03\" \"2026-03-04\" \"2026-03-05\" \"2026-03-06\"\n [66] \"2026-03-07\" \"2026-03-08\" \"2026-03-09\" \"2026-03-10\" \"2026-03-11\"\n [71] \"2026-03-12\" \"2026-03-13\" \"2026-03-14\" \"2026-03-15\" \"2026-03-16\"\n [76] \"2026-03-17\" \"2026-03-18\" \"2026-03-19\" \"2026-03-20\" \"2026-03-21\"\n [81] \"2026-03-22\" \"2026-03-23\" \"2026-03-24\" \"2026-03-25\" \"2026-03-26\"\n [86] \"2026-03-27\" \"2026-03-28\" \"2026-03-29\" \"2026-03-30\" \"2026-03-31\"\n [91] \"2026-04-01\" \"2026-04-02\" \"2026-04-03\" \"2026-04-04\" \"2026-04-05\"\n [96] \"2026-04-06\" \"2026-04-07\" \"2026-04-08\" \"2026-04-09\" \"2026-04-10\"\n[101] \"2026-04-11\" \"2026-04-12\" \"2026-04-13\" \"2026-04-14\" \"2026-04-15\"\n[106] \"2026-04-16\" \"2026-04-17\" \"2026-04-18\" \"2026-04-19\" \"2026-04-20\"\n[111] \"2026-04-21\" \"2026-04-22\" \"2026-04-23\" \"2026-04-24\" \"2026-04-25\"\n[116] \"2026-04-26\" \"2026-04-27\" \"2026-04-28\" \"2026-04-29\" \"2026-04-30\"\n[121] \"2026-05-01\" \"2026-05-02\" \"2026-05-03\" \"2026-05-04\" \"2026-05-05\"\n[126] \"2026-05-06\" \"2026-05-07\" \"2026-05-08\" \"2026-05-09\" \"2026-05-10\"\n[131] \"2026-05-11\" \"2026-05-12\" \"2026-05-13\" \"2026-05-14\" \"2026-05-15\"\n[136] \"2026-05-16\" \"2026-05-17\" \"2026-05-18\" \"2026-05-19\" \"2026-05-20\"\n[141] \"2026-05-21\" \"2026-05-22\" \"2026-05-23\" \"2026-05-24\" \"2026-05-25\"\n[146] \"2026-05-26\" \"2026-05-27\" \"2026-05-28\" \"2026-05-29\" \"2026-05-30\"\n[151] \"2026-05-31\" \"2026-06-01\" \"2026-06-02\" \"2026-06-03\" \"2026-06-04\"\n[156] \"2026-06-05\" \"2026-06-06\" \"2026-06-07\" \"2026-06-08\" \"2026-06-09\"\n[161] \"2026-06-10\" \"2026-06-11\" \"2026-06-12\" \"2026-06-13\" \"2026-06-14\"\n[166] \"2026-06-15\" \"2026-06-16\" \"2026-06-17\" \"2026-06-18\" \"2026-06-19\"\n[171] \"2026-06-20\" \"2026-06-21\" \"2026-06-22\" \"2026-06-23\" \"2026-06-24\"\n[176] \"2026-06-25\" \"2026-06-26\" \"2026-06-27\" \"2026-06-28\" \"2026-06-29\"\n[181] \"2026-06-30\" \"2026-07-01\" \"2026-07-02\" \"2026-07-03\" \"2026-07-04\"\n[186] \"2026-07-05\" \"2026-07-06\" \"2026-07-07\" \"2026-07-08\" \"2026-07-09\"\n[191] \"2026-07-10\" \"2026-07-11\" \"2026-07-12\" \"2026-07-13\" \"2026-07-14\"\n[196] \"2026-07-15\" \"2026-07-16\" \"2026-07-17\" \"2026-07-18\" \"2026-07-19\"\n[201] \"2026-07-20\" \"2026-07-21\" \"2026-07-22\" \"2026-07-23\" \"2026-07-24\"\n[206] \"2026-07-25\" \"2026-07-26\" \"2026-07-27\" \"2026-07-28\" \"2026-07-29\"\n[211] \"2026-07-30\" \"2026-07-31\" \"2026-08-01\" \"2026-08-02\" \"2026-08-03\"\n[216] \"2026-08-04\" \"2026-08-05\" \"2026-08-06\" \"2026-08-07\" \"2026-08-08\"\n[221] \"2026-08-09\" \"2026-08-10\" \"2026-08-11\" \"2026-08-12\" \"2026-08-13\"\n[226] \"2026-08-14\" \"2026-08-15\" \"2026-08-16\" \"2026-08-17\" \"2026-08-18\"\n[231] \"2026-08-19\" \"2026-08-20\" \"2026-08-21\" \"2026-08-22\" \"2026-08-23\"\n[236] \"2026-08-24\" \"2026-08-25\" \"2026-08-26\" \"2026-08-27\" \"2026-08-28\"\n[241] \"2026-08-29\" \"2026-08-30\" \"2026-08-31\" \"2026-09-01\" \"2026-09-02\"\n[246] \"2026-09-03\" \"2026-09-04\" \"2026-09-05\" \"2026-09-06\" \"2026-09-07\"\n[251] \"2026-09-08\" \"2026-09-09\" \"2026-09-10\" \"2026-09-11\" \"2026-09-12\"\n[256] \"2026-09-13\" \"2026-09-14\" \"2026-09-15\" \"2026-09-16\" \"2026-09-17\"\n[261] \"2026-09-18\" \"2026-09-19\" \"2026-09-20\" \"2026-09-21\" \"2026-09-22\"\n[266] \"2026-09-23\" \"2026-09-24\" \"2026-09-25\" \"2026-09-26\" \"2026-09-27\"\n[271] \"2026-09-28\" \"2026-09-29\" \"2026-09-30\" \"2026-10-01\" \"2026-10-02\"\n[276] \"2026-10-03\" \"2026-10-04\" \"2026-10-05\" \"2026-10-06\" \"2026-10-07\"\n[281] \"2026-10-08\" \"2026-10-09\" \"2026-10-10\" \"2026-10-11\" \"2026-10-12\"\n[286] \"2026-10-13\" \"2026-10-14\" \"2026-10-15\" \"2026-10-16\" \"2026-10-17\"\n[291] \"2026-10-18\" \"2026-10-19\" \"2026-10-20\" \"2026-10-21\" \"2026-10-22\"\n[296] \"2026-10-23\" \"2026-10-24\" \"2026-10-25\" \"2026-10-26\" \"2026-10-27\"\n[301] \"2026-10-28\" \"2026-10-29\" \"2026-10-30\" \"2026-10-31\" \"2026-11-01\"\n[306] \"2026-11-02\" \"2026-11-03\" \"2026-11-04\" \"2026-11-05\" \"2026-11-06\"\n[311] \"2026-11-07\" \"2026-11-08\" \"2026-11-09\" \"2026-11-10\" \"2026-11-11\"\n[316] \"2026-11-12\" \"2026-11-13\" \"2026-11-14\" \"2026-11-15\" \"2026-11-16\"\n[321] \"2026-11-17\" \"2026-11-18\" \"2026-11-19\" \"2026-11-20\" \"2026-11-21\"\n[326] \"2026-11-22\" \"2026-11-23\" \"2026-11-24\" \"2026-11-25\" \"2026-11-26\"\n[331] \"2026-11-27\" \"2026-11-28\" \"2026-11-29\" \"2026-11-30\" \"2026-12-01\"\n[336] \"2026-12-02\" \"2026-12-03\" \"2026-12-04\" \"2026-12-05\" \"2026-12-06\"\n[341] \"2026-12-07\" \"2026-12-08\" \"2026-12-09\" \"2026-12-10\" \"2026-12-11\"\n[346] \"2026-12-12\" \"2026-12-13\" \"2026-12-14\" \"2026-12-15\" \"2026-12-16\"\n[351] \"2026-12-17\" \"2026-12-18\" \"2026-12-19\" \"2026-12-20\" \"2026-12-21\"\n[356] \"2026-12-22\" \"2026-12-23\" \"2026-12-24\" \"2026-12-25\" \"2026-12-26\"\n[361] \"2026-12-27\" \"2026-12-28\" \"2026-12-29\" \"2026-12-30\" \"2026-12-31\"\n[366] \"2027-01-01\"\n\n\n\n\n\n\nExercises\nLoad the diamonds dataset, and filter to the first 1000 diamonds.\n\nCodedata(diamonds)\ndiamonds &lt;- diamonds |&gt; \n    slice_head(n = 1000)\n\n\nUsing tidyverse functions, complete the following:\n\nSubset to diamonds that are less than 400 dollars or more than 10000 dollars.\nSubset to diamonds that are between 500 and 600 dollars (inclusive).\nHow many diamonds are of either Fair, Premium, or Ideal cut (a total count)? What fraction of diamonds are of Fair, Premium, or Ideal cut?\n\nFirst, do this a wrong way with ==. Predict the warning message that you will receive.\nSecond, do this the correct way with an appropriate logical operator.\n\n\nAre there any diamonds of Fair cut that are more than $3000? Are all diamonds of Ideal cut more than $2000?\nCreate two new categorized versions of price by looking up the documentation for if_else() and case_when():\n\n\nprice_cat1: ‚Äúlow‚Äù if price is less than 500 and ‚Äúhigh‚Äù otherwise\n\nprice_cat2: ‚Äúlow‚Äù if price is less than 500, ‚Äúmedium‚Äù if price is between 500 and 1000 dollars inclusive, and ‚Äúhigh‚Äù otherwise.\n\n\n\n\nCode# 1\ndiamonds |&gt; \n    filter(price &lt; 400 | price &gt; 10000)\n\n# A tibble: 30 √ó 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ‚Ñπ 20 more rows\n\nCode# 2\ndiamonds |&gt; \n    filter(price &gt;= 500, price &lt;= 600)\n\n# A tibble: 90 √ó 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.35 Ideal     I     VS1      60.9  57     552  4.54  4.59  2.78\n 2  0.3  Premium   D     SI1      62.6  59     552  4.23  4.27  2.66\n 3  0.3  Ideal     D     SI1      62.5  57     552  4.29  4.32  2.69\n 4  0.3  Ideal     D     SI1      62.1  56     552  4.3   4.33  2.68\n 5  0.42 Premium   I     SI2      61.5  59     552  4.78  4.84  2.96\n 6  0.28 Ideal     G     VVS2     61.4  56     553  4.19  4.22  2.58\n 7  0.32 Ideal     I     VVS1     62    55.3   553  4.39  4.42  2.73\n 8  0.31 Very Good G     SI1      63.3  57     553  4.33  4.3   2.73\n 9  0.31 Premium   G     SI1      61.8  58     553  4.35  4.32  2.68\n10  0.24 Premium   E     VVS1     60.7  58     553  4.01  4.03  2.44\n# ‚Ñπ 80 more rows\n\nCode# 3\n## Wrong way with ==\ndiamonds |&gt; \n    mutate(is_fpi = cut == c(\"Fair\", \"Premium\", \"Ideal\")) |&gt; \n    summarize(num_fpi = sum(is_fpi), frac_fpi = mean(is_fpi))\n\n# A tibble: 1 √ó 2\n  num_fpi frac_fpi\n    &lt;int&gt;    &lt;dbl&gt;\n1     226    0.226\n\nCode## Right way with %in%\ndiamonds |&gt; \n    mutate(is_fpi = cut %in% c(\"Fair\", \"Premium\", \"Ideal\")) |&gt; \n    summarize(num_fpi = sum(is_fpi), frac_fpi = mean(is_fpi))\n\n# A tibble: 1 √ó 2\n  num_fpi frac_fpi\n    &lt;int&gt;    &lt;dbl&gt;\n1     685    0.685\n\nCode# 4\ndiamonds |&gt; \n    filter(cut == \"Fair\") |&gt; \n    summarize(any_high = any(price &gt; 3000))\n\n# A tibble: 1 √ó 1\n  any_high\n  &lt;lgl&gt;   \n1 FALSE   \n\nCodediamonds |&gt; \n    filter(cut == \"Ideal\") |&gt; \n    summarize(all_high = all(price &gt; 2000))\n\n# A tibble: 1 √ó 1\n  all_high\n  &lt;lgl&gt;   \n1 FALSE   \n\nCode# 5\ndiamonds |&gt; \n    mutate(\n        price_cat1 = if_else(price &lt; 500, \"low\", \"high\"),\n        price_cat2 = case_when(\n            price &lt; 500 ~ \"low\",\n            price &gt;= 500 & price &lt;= 1000 ~ \"medium\",\n            price &gt; 1000 ~ \"high\"\n        )\n    )\n\n# A tibble: 1,000 √ó 12\n   carat cut       color clarity depth table price     x     y     z price_cat1\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43 low       \n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31 low       \n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31 low       \n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63 low       \n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75 low       \n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48 low       \n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47 low       \n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53 low       \n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49 low       \n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39 low       \n# ‚Ñπ 990 more rows\n# ‚Ñπ 1 more variable: price_cat2 &lt;chr&gt;",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>6 Adv Data wrangling I</span>"
    ]
  },
  {
    "objectID": "ica/06-wrangling-1-notes.html#numerics",
    "href": "ica/06-wrangling-1-notes.html#numerics",
    "title": "6 Adv Data wrangling I",
    "section": "Numerics",
    "text": "Numerics\nNotes\nNumerical data can be of class integer or numeric (representing real numbers).\n\nCodex &lt;- 1:3\nx\n\n[1] 1 2 3\n\nCodeclass(x)\n\n[1] \"integer\"\n\nCodex &lt;- c(1+1e-9, 2, 3)\nx\n\n[1] 1 2 3\n\nCodeclass(x)\n\n[1] \"numeric\"\n\n\nThe Numbers chapter in R4DS covers the following functions that are all useful for wrangling numeric data:\n\n\nn(), n_distinct(): Counting and counting the number of unique values\n\nsum(is.na()): Counting the number of missing values\n\nmin(), max()\n\n\npmin(), pmax(): Get the min and max across several vectors\nInteger division: %/%. Remainder: %%\n\n\n121 %/% 100 = 1 and 121 %% 100 = 21\n\n\n\n\nround(), floor(), ceiling(): Rounding functions (to a specified number of decimal places, to the largest integer below a number, to the smallest integer above a number)\n\ncut(): Cut a numerical vector into categories\n\ncumsum(), cummean(), cummin(), cummax(): Cumulative functions\n\nrank(): Provide the ranks of the numbers in a vector\n\nlead(), lag(): shift a vector by padding with NAs\nNumerical summaries: mean, median, min, max, quantile, sd, IQR\n\nNote that all numerical summary functions have an na.rm argument that should be set to TRUE if you have missing data.\n\n\nExercises\nExercises will be on HW4.\nThe best way to add these functions and operators to your vocabulary is to need to recall them. Refer to the list of functions above as you try the exercises.\nYou will need to reference function documentation to look at arguments and look in the Examples section.",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>6 Adv Data wrangling I</span>"
    ]
  },
  {
    "objectID": "ica/06-wrangling-1-notes.html#dates",
    "href": "ica/06-wrangling-1-notes.html#dates",
    "title": "6 Adv Data wrangling I",
    "section": "Dates",
    "text": "Dates\nNotes\nThe lubridate package contains useful functions for working with dates and times. The lubridate function reference is a useful resource for finding the functions you need. We‚Äôll take a brief tour of this reference page.\nWe‚Äôll use the lakers dataset in the lubridate package to illustrate some examples.\n\nCodelakers &lt;- as_tibble(lakers)\nhead(lakers)\n\n# A tibble: 6 √ó 13\n     date opponent game_type time  period etype team  player result points type \n    &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;\n1  2.01e7 POR      home      12:00      1 jump‚Ä¶ OFF   \"\"     \"\"          0 \"\"   \n2  2.01e7 POR      home      11:39      1 shot  LAL   \"Pau ‚Ä¶ \"miss‚Ä¶      0 \"hoo‚Ä¶\n3  2.01e7 POR      home      11:37      1 rebo‚Ä¶ LAL   \"Vlad‚Ä¶ \"\"          0 \"off\"\n4  2.01e7 POR      home      11:25      1 shot  LAL   \"Dere‚Ä¶ \"miss‚Ä¶      0 \"lay‚Ä¶\n5  2.01e7 POR      home      11:23      1 rebo‚Ä¶ LAL   \"Pau ‚Ä¶ \"\"          0 \"off\"\n6  2.01e7 POR      home      11:22      1 shot  LAL   \"Pau ‚Ä¶ \"made\"      2 \"hoo‚Ä¶\n# ‚Ñπ 2 more variables: x &lt;int&gt;, y &lt;int&gt;\n\n\nBelow we use date-time parsing functions to represent the date and time variables with date-time classes:\n\nCodelakers &lt;- lakers |&gt;\n    mutate(\n        date = ymd(date),\n        time = ms(time)\n    )\n\n\nBelow we use extraction functions to get components of the date-time objects:\n\nCodelakers_clean &lt;- lakers |&gt;\n    mutate(\n        year = year(date),\n        month = month(date),\n        day = day(date),\n        day_of_week = wday(date, label = TRUE),\n        minute = minute(time),\n        second = second(time)\n    )\nlakers_clean |&gt; select(year:second)\n\n# A tibble: 34,624 √ó 6\n    year month   day day_of_week minute second\n   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;ord&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n 1  2008    10    28 Tue             12      0\n 2  2008    10    28 Tue             11     39\n 3  2008    10    28 Tue             11     37\n 4  2008    10    28 Tue             11     25\n 5  2008    10    28 Tue             11     23\n 6  2008    10    28 Tue             11     22\n 7  2008    10    28 Tue             11     22\n 8  2008    10    28 Tue             11     22\n 9  2008    10    28 Tue             11      0\n10  2008    10    28 Tue             10     53\n# ‚Ñπ 34,614 more rows\n\nCodelakers_clean &lt;- lakers_clean |&gt;\n    group_by(date, opponent, period) |&gt;\n    arrange(date, opponent, period, desc(time)) |&gt;\n    mutate(\n        diff_btw_plays_sec = as.numeric(time - lag(time, 1))\n    )\nlakers_clean |&gt; select(date, opponent, time, period, diff_btw_plays_sec)\n\n# A tibble: 34,624 √ó 5\n# Groups:   date, opponent, period [314]\n   date       opponent time     period diff_btw_plays_sec\n   &lt;date&gt;     &lt;chr&gt;    &lt;Period&gt;  &lt;int&gt;              &lt;dbl&gt;\n 1 2008-10-28 POR      12M 0S        1                 NA\n 2 2008-10-28 POR      11M 39S       1                -21\n 3 2008-10-28 POR      11M 37S       1                 -2\n 4 2008-10-28 POR      11M 25S       1                -12\n 5 2008-10-28 POR      11M 23S       1                 -2\n 6 2008-10-28 POR      11M 22S       1                 -1\n 7 2008-10-28 POR      11M 22S       1                  0\n 8 2008-10-28 POR      11M 22S       1                  0\n 9 2008-10-28 POR      11M 0S        1                -22\n10 2008-10-28 POR      10M 53S       1                 -7\n# ‚Ñπ 34,614 more rows\n\n\nExercises\nExercises will be on HW4.",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>6 Adv Data wrangling I</span>"
    ]
  },
  {
    "objectID": "ica/06-wrangling-1-notes.html#factors",
    "href": "ica/06-wrangling-1-notes.html#factors",
    "title": "6 Adv Data wrangling I",
    "section": "Factors",
    "text": "Factors\nNotes\nCreating factors\nIn R, factors are made up of two components: the actual values of the data and the possible levels within the factor. Creating a factor requires supplying both pieces of information.\n\nCodemonths &lt;- c(\"Mar\", \"Dec\", \"Jan\",  \"Apr\", \"Jul\")\n\n\nHowever, if we were to sort this vector, R would sort this vector alphabetically.\n\nCode# alphabetical sort\nsort(months)\n\n[1] \"Apr\" \"Dec\" \"Jan\" \"Jul\" \"Mar\"\n\n\nWe can fix this sorting by creating a factor version of months. The levels argument is a character vector that specifies the unique values that the factor can take. The order of the values in levels defines the sorting of the factor.\n\nCodemonths_fct &lt;- factor(months, levels = month.abb) # month.abb is a built-in variable\nmonths_fct\n\n[1] Mar Dec Jan Apr Jul\nLevels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\nCodesort(months_fct)\n\n[1] Jan Mar Apr Jul Dec\nLevels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\n\nWhat if we try to create a factor with values that aren‚Äôt in the levels? (e.g., a typo in a month name)\n\nCodemonths2 &lt;- c(\"Jna\", \"Mar\")\nfactor(months2, levels = month.abb)\n\n[1] &lt;NA&gt; Mar \nLevels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\n\nBecause the NA is introduced silently (without any error or warnings), this can be dangerous. It might be better to use the fct() function in the forcats package instead:\n\nCodefct(months2, levels = month.abb)\n\nError in `fct()`:\n! All values of `x` must appear in `levels` or `na`\n‚Ñπ Missing level: \"Jna\"\n\n\nReordering factors\nWe‚Äôll use a subset of the General Social Survey (GSS) dataset available in the forcats pacakges.\n\nCodedata(gss_cat)\nhead(gss_cat)\n\n# A tibble: 6 √ó 9\n   year marital         age race  rincome        partyid     relig denom tvhours\n  &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;       &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n1  2000 Never married    26 White $8000 to 9999  Ind,near r‚Ä¶ Prot‚Ä¶ Sout‚Ä¶      12\n2  2000 Divorced         48 White $8000 to 9999  Not str re‚Ä¶ Prot‚Ä¶ Bapt‚Ä¶      NA\n3  2000 Widowed          67 White Not applicable Independent Prot‚Ä¶ No d‚Ä¶       2\n4  2000 Never married    39 White Not applicable Ind,near r‚Ä¶ Orth‚Ä¶ Not ‚Ä¶       4\n5  2000 Divorced         25 White Not applicable Not str de‚Ä¶ None  Not ‚Ä¶       1\n6  2000 Married          25 White $20000 - 24999 Strong dem‚Ä¶ Prot‚Ä¶ Sout‚Ä¶      NA\n\n\nReordering the levels of a factor can be useful in plotting when categories would benefit from being sorted in a particular way:\n\nCoderelig_summary &lt;- gss_cat |&gt;\n    group_by(relig) |&gt;\n    summarize(\n        tvhours = mean(tvhours, na.rm = TRUE),\n        n = n()\n    )\n\nggplot(relig_summary, aes(x = tvhours, y = relig)) + \n    geom_point() +\n    theme_classic()\n\n\n\n\n\n\n\nWe can use fct_reorder() in forcats.\n\nThe first argument is the factor that you want to reorder the levels of\nThe second argument determines how the factor is sorted (analogous to what you put inside arrange() when sorting the rows of a data frame.)\n\n\nCodeggplot(relig_summary, aes(x = tvhours, y = fct_reorder(relig, tvhours))) +\n    geom_point() +\n    theme_classic()\n\n\n\n\n\n\n\nFor bar plots, we can use fct_infreq() to reorder levels from most to least common. This can be combined with fct_rev() to reverse the order (least to most common):\n\nCodegss_cat |&gt;\n    ggplot(aes(x = marital)) +\n    geom_bar() +\n    theme_classic()\n\n\n\n\n\n\nCodegss_cat |&gt;\n    mutate(marital = marital |&gt; fct_infreq() |&gt; fct_rev()) |&gt;\n    ggplot(aes(x = marital)) +\n    geom_bar() +\n    theme_classic()\n\n\n\n\n\n\n\nModifying factor levels\nWe talked about reordering the levels of a factor‚Äìwhat about changing the values of the levels themselves?\nFor example, the names of the political parties in the GSS could use elaboration (‚Äústr‚Äù isn‚Äôt a great label for ‚Äústrong‚Äù) and clean up:\n\nCodegss_cat |&gt; count(partyid)\n\n# A tibble: 10 √ó 2\n   partyid                n\n   &lt;fct&gt;              &lt;int&gt;\n 1 No answer            154\n 2 Don't know             1\n 3 Other party          393\n 4 Strong republican   2314\n 5 Not str republican  3032\n 6 Ind,near rep        1791\n 7 Independent         4119\n 8 Ind,near dem        2499\n 9 Not str democrat    3690\n10 Strong democrat     3490\n\n\nWe can use fct_recode() on partyid with the new level names going on the left and the old levels on the right. Any levels that aren‚Äôt mentioned explicitly (i.e., ‚ÄúDon‚Äôt know‚Äù and ‚ÄúOther party‚Äù) will be left as is:\n\nCodegss_cat |&gt;\n    mutate(\n        partyid = fct_recode(partyid,\n            \"Republican, strong\"    = \"Strong republican\",\n            \"Republican, weak\"      = \"Not str republican\",\n            \"Independent, near rep\" = \"Ind,near rep\",\n            \"Independent, near dem\" = \"Ind,near dem\",\n            \"Democrat, weak\"        = \"Not str democrat\",\n            \"Democrat, strong\"      = \"Strong democrat\"\n        )\n    ) |&gt;\n    count(partyid)\n\n# A tibble: 10 √ó 2\n   partyid                   n\n   &lt;fct&gt;                 &lt;int&gt;\n 1 No answer               154\n 2 Don't know                1\n 3 Other party             393\n 4 Republican, strong     2314\n 5 Republican, weak       3032\n 6 Independent, near rep  1791\n 7 Independent            4119\n 8 Independent, near dem  2499\n 9 Democrat, weak         3690\n10 Democrat, strong       3490\n\n\nTo combine groups, we can assign multiple old levels to the same new level (‚ÄúOther‚Äù maps to ‚ÄúNo answer‚Äù, ‚ÄúDon‚Äôt know‚Äù, and ‚ÄúOther party‚Äù):\n\nCodegss_cat |&gt;\n    mutate(\n        partyid = fct_recode(partyid,\n            \"Republican, strong\"    = \"Strong republican\",\n            \"Republican, weak\"      = \"Not str republican\",\n            \"Independent, near rep\" = \"Ind,near rep\",\n            \"Independent, near dem\" = \"Ind,near dem\",\n            \"Democrat, weak\"        = \"Not str democrat\",\n            \"Democrat, strong\"      = \"Strong democrat\",\n            \"Other\"                 = \"No answer\",\n            \"Other\"                 = \"Don't know\",\n            \"Other\"                 = \"Other party\"\n        )\n    )\n\n# A tibble: 21,483 √ó 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Independe‚Ä¶ Prot‚Ä¶ Sout‚Ä¶      12\n 2  2000 Divorced         48 White $8000 to 9999  Republica‚Ä¶ Prot‚Ä¶ Bapt‚Ä¶      NA\n 3  2000 Widowed          67 White Not applicable Independe‚Ä¶ Prot‚Ä¶ No d‚Ä¶       2\n 4  2000 Never married    39 White Not applicable Independe‚Ä¶ Orth‚Ä¶ Not ‚Ä¶       4\n 5  2000 Divorced         25 White Not applicable Democrat,‚Ä¶ None  Not ‚Ä¶       1\n 6  2000 Married          25 White $20000 - 24999 Democrat,‚Ä¶ Prot‚Ä¶ Sout‚Ä¶      NA\n 7  2000 Never married    36 White $25000 or more Republica‚Ä¶ Chri‚Ä¶ Not ‚Ä¶       3\n 8  2000 Divorced         44 White $7000 to 7999  Independe‚Ä¶ Prot‚Ä¶ Luth‚Ä¶      NA\n 9  2000 Married          44 White $25000 or more Democrat,‚Ä¶ Prot‚Ä¶ Other       0\n10  2000 Married          47 White $25000 or more Republica‚Ä¶ Prot‚Ä¶ Sout‚Ä¶       3\n# ‚Ñπ 21,473 more rows\n\n\nWe can use fct_collapse() to collapse many levels:\n\nCodegss_cat |&gt;\n    mutate(\n        partyid = fct_collapse(partyid,\n            \"Other\" = c(\"No answer\", \"Don't know\", \"Other party\"),\n            \"Republican\" = c(\"Strong republican\", \"Not str republican\"),\n            \"Independent\" = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n            \"Democrat\" = c(\"Not str democrat\", \"Strong democrat\")\n        )\n    ) |&gt;\n    count(partyid)\n\n# A tibble: 4 √ó 2\n  partyid         n\n  &lt;fct&gt;       &lt;int&gt;\n1 Other         548\n2 Republican   5346\n3 Independent  8409\n4 Democrat     7180\n\n\nExercises\n\nCreate a factor version of the following data with the levels in a sensible order.\n\n\nCoderatings &lt;- c(\"High\", \"Medium\", \"Low\")\n\n\nMore exercises will be on HW4.",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>6 Adv Data wrangling I</span>"
    ]
  },
  {
    "objectID": "ica/06-wrangling-1-notes.html#done",
    "href": "ica/06-wrangling-1-notes.html#done",
    "title": "6 Adv Data wrangling I",
    "section": "Done!",
    "text": "Done!\n\nCheck the ICA Instructions for how to (a) push your code to GitHub and (b) update your portfolio website",
    "crumbs": [
      "In-Class Activities",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>6 Adv Data wrangling I</span>"
    ]
  },
  {
    "objectID": "extra/extra-sample1.html",
    "href": "extra/extra-sample1.html",
    "title": "Extra Sample 1",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Extras",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Extra Sample 1</span>"
    ]
  },
  {
    "objectID": "extra/extra-sample2.html",
    "href": "extra/extra-sample2.html",
    "title": "Extra Sample 2",
    "section": "",
    "text": "Add content here",
    "crumbs": [
      "Extras",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Extra Sample 2</span>"
    ]
  }
]